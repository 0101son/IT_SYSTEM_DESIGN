{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 개요\n",
        "이 노트북은 HW4의 결과로 얻은 최적의 파라미터로 모델을 훈련시키는 과정을 재현합니다.\n",
        "\n",
        "훈련 과정의 무작위성을 감안하여 같은 하이퍼파라미터로 3번 훈련시킵니다.\n",
        "\n",
        "# 사용법\n",
        "처음부터 끝까지 실행시키면 됩니다.\n",
        "\n",
        "# ❗주의 ❗\n",
        "마찬가지의 이유로 구글 계정 및 구글 드라이브 연동이 필요합니다."
      ],
      "metadata": {
        "id": "4-yE5PZLcgXc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9pHFZYvpDbQ",
        "outputId": "0caa47bd-7e0a-46d3-cfa3-80ae218b782a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atOQgH3OpKca",
        "outputId": "2bc9506a-3e6e-41be-dd2e-4290c9c1cb2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hpbandster\n",
            "  Downloading hpbandster-0.7.4.tar.gz (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Pyro4 (from hpbandster)\n",
            "  Downloading Pyro4-4.82-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting serpent (from hpbandster)\n",
            "  Downloading serpent-1.41-py3-none-any.whl (9.6 kB)\n",
            "Collecting ConfigSpace (from hpbandster)\n",
            "  Downloading ConfigSpace-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hpbandster) (1.25.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from hpbandster) (0.14.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hpbandster) (1.11.4)\n",
            "Collecting netifaces (from hpbandster)\n",
            "  Downloading netifaces-0.11.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->hpbandster) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->hpbandster) (4.12.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from ConfigSpace->hpbandster) (10.1.0)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels->hpbandster) (2.0.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->hpbandster) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->hpbandster) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels->hpbandster) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->hpbandster) (1.16.0)\n",
            "Building wheels for collected packages: hpbandster, netifaces\n",
            "  Building wheel for hpbandster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hpbandster: filename=hpbandster-0.7.4-py3-none-any.whl size=79991 sha256=4b7e0af38f651c1798ee1040fd4def5ce76ec42fd3c6faf7e3137922443e9e5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/51/18/33d6ba8c55cc8401bffbccb1b87b21e0c68f40edc4ce3c1f99\n",
            "  Building wheel for netifaces (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for netifaces: filename=netifaces-0.11.0-cp310-cp310-linux_x86_64.whl size=35008 sha256=a7c9dfe27e917686ec0f7c64c2c9dbd6045eed29e68ae268bc7694374e894f55\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/65/b3/4c4cc6038b81ff21cc9df69f2b6774f5f52e23d3c275ed15aa\n",
            "Successfully built hpbandster netifaces\n",
            "Installing collected packages: netifaces, serpent, Pyro4, ConfigSpace, hpbandster\n",
            "Successfully installed ConfigSpace-0.7.1 Pyro4-4.82 hpbandster-0.7.4 netifaces-0.11.0 serpent-1.41\n",
            "Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (1.25.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (3.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (1.11.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (4.12.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from ConfigSpace) (10.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install hpbandster\n",
        "!pip install ConfigSpace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tjDvD2kepMbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec12b82-627d-418c-95d4-222bd7e859d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터셋 로드\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 데이터 전처리\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 2.4. train data를 4:1로 분할하여 validation data 생성\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7yMLpfiKpQwj"
      },
      "outputs": [],
      "source": [
        "# 3. 데이터 증강\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    fill_mode = 'nearest'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8uxmLnPydcK"
      },
      "source": [
        "# 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AkE57b5S9UUw"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models, regularizers, optimizers, callbacks, metrics\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dropout, Dense, Add, DepthwiseConv2D\n",
        "def inverted_residual_block(inputs, filters, stride, expansion, l2):\n",
        "    x = inputs\n",
        "    in_channels = x.shape[-1]\n",
        "    x = Conv2D(expansion * in_channels, kernel_size=1, padding='same', use_bias=False, kernel_regularizer=tf.keras.regularizers.l2(l2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU(6.)(x)\n",
        "\n",
        "    x = DepthwiseConv2D(kernel_size=3, strides=stride, padding='same', use_bias=False, kernel_regularizer=tf.keras.regularizers.l2(l2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU(6.)(x)\n",
        "\n",
        "    x = Conv2D(filters, kernel_size=1, padding='same', use_bias=False, kernel_regularizer=tf.keras.regularizers.l2(l2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    if stride == 1 and in_channels == filters:\n",
        "        x = Add()([inputs, x])\n",
        "\n",
        "    return x\n",
        "\n",
        "def MobileNetV2(input_shape=(28, 28, 1), num_classes=10, expansion=3, dropout=0.2, l2=0.003):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(16, kernel_size=3, strides=2, padding='same', use_bias=False, kernel_regularizer=tf.keras.regularizers.l2(l2))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU(6.)(x)\n",
        "\n",
        "    x = inverted_residual_block(x, filters=16, stride=1, expansion=1, l2=l2)\n",
        "\n",
        "    x = inverted_residual_block(x, filters=24, stride=1, expansion=expansion, l2=l2)\n",
        "    x = inverted_residual_block(x, filters=24, stride=1, expansion=expansion, l2=l2)\n",
        "\n",
        "    x = inverted_residual_block(x, filters=32, stride=2, expansion=expansion, l2=l2)\n",
        "    x = inverted_residual_block(x, filters=32, stride=1, expansion=expansion, l2=l2)\n",
        "    x = inverted_residual_block(x, filters=32, stride=1, expansion=expansion, l2=l2)\n",
        "\n",
        "    x = inverted_residual_block(x, filters=64, stride=1, expansion=expansion, l2=l2)\n",
        "\n",
        "    x = Conv2D(256, kernel_size=1, use_bias=False, kernel_regularizer=tf.keras.regularizers.l2(l2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU(6.)(x)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    x = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, x)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(\n",
        "\tmomentum=0.9,\n",
        "\tinitial_lr=0.001,\n",
        "\treduce_lr_factor=0.9,\n",
        "\treduce_lr_patience=6,\n",
        "\texpansion=3,\n",
        "\tdropout=0.2,\n",
        "\tl2=0.003,\n",
        "):\n",
        "\tmodel = MobileNetV2(expansion = expansion,dropout=dropout,l2=l2)\n",
        "\n",
        "\toptimizer=optimizers.RMSprop(\n",
        "\t\tlearning_rate = initial_lr,\n",
        "\t\tmomentum=momentum,\n",
        "\t)\n",
        "\n",
        "\tmodel.compile(\n",
        "\t\toptimizer=optimizer,\n",
        "\t\tloss='categorical_crossentropy',\n",
        "\t\tmetrics=['categorical_accuracy']\n",
        "\t)\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "CNBqmbR8ooeA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJk7iRIy9dzN"
      },
      "source": [
        "# 훈련 과정 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CTu_ibgV9dc7"
      },
      "outputs": [],
      "source": [
        "import ConfigSpace as CS\n",
        "import ConfigSpace.hyperparameters as CSH\n",
        "import torch\n",
        "\n",
        "import tensorflow as tf\n",
        "from hpbandster.core.worker import Worker\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "class MyWorker(Worker):\n",
        "    def compute(self, config, budget, *args, **kwargs):\n",
        "\n",
        "        print(\"Hyperparameters:\", config)  # 현재 하이퍼파라미터 출력\n",
        "\n",
        "        # 하이퍼파라미터들\n",
        "        momentum = config['momentum']\n",
        "        initial_lr = config['initial_lr']\n",
        "        #batch_size = 2 ** config['batch_size_exp']\n",
        "        #expansion = config['expansion']\n",
        "        dropout = config['dropout']\n",
        "        #reduce_lr_patience = config['reduce_lr_patience']\n",
        "        reduce_lr_factor = config['reduce_lr_factor']\n",
        "        l2 = config['l2']\n",
        "\n",
        "        # 실험 내용 재현을 위한 하이퍼 파라미터 고정 - 필요 시 삭제\n",
        "\n",
        "        #momentum = 0.999\n",
        "        #initial_lr = 3.593e-5\n",
        "        batch_size = 2 ** 8\n",
        "        expansion = 6\n",
        "        #dropout = 0.141\n",
        "        reduce_lr_patience = 4\n",
        "        #reduce_lr_factor = 0.577\n",
        "        #l2 = 2.213e-5\n",
        "\n",
        "        # 모델 생성\n",
        "        model = create_model(\n",
        "            momentum=momentum,\n",
        "\t\t\tinitial_lr=initial_lr,\n",
        "\t\t\treduce_lr_factor=reduce_lr_factor,\n",
        "\t\t\treduce_lr_patience=reduce_lr_patience,\n",
        "\t\t\texpansion=expansion,\n",
        "\t\t\tdropout=dropout,\n",
        "\t\t\tl2=l2,\n",
        "        )\n",
        "\n",
        "        # EarlyStopping 콜백 정의\n",
        "        early_stopping = EarlyStopping(\n",
        "            monitor='val_categorical_accuracy',  # 검증 손실 기반으로 모니터링\n",
        "            patience=10,  # 10 에폭 동안 성능 향상이 없으면 학습 조기 종료\n",
        "            restore_best_weights=True,  # 최적의 가중치로 복원\n",
        "        )\n",
        "\n",
        "        # ReduceLROnPlateau 콜백 정의\n",
        "        reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_categorical_accuracy',\n",
        "            factor=reduce_lr_factor,\n",
        "            patience=reduce_lr_patience,\n",
        "        )\n",
        "        model.fit(\n",
        "            datagen.flow(x_train.reshape(-1, 28, 28, 1), y_train, batch_size=batch_size),  # 데이터 증강 적용\n",
        "            epochs=int(budget),\n",
        "            verbose=1,\n",
        "            validation_data=(x_val.reshape(-1, 28, 28, 1), y_val),\n",
        "            callbacks=[reduce_lr, early_stopping],\n",
        "        )\n",
        "\n",
        "        loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
        "        return {'loss': -accuracy, 'info': {'test_accuracy': accuracy}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn-SkURpggt9"
      },
      "source": [
        "# 하이퍼파라미터 범위 설정\n",
        "실험 결과 얻어낸 하이퍼파라미터를 그대로 입력하여 재현합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dhcNbp4Oge5E"
      },
      "outputs": [],
      "source": [
        "import ConfigSpace as CS\n",
        "import ConfigSpace.hyperparameters as CSH\n",
        "def get_configspace():\n",
        "    cs = CS.ConfigurationSpace()\n",
        "\n",
        "    # 하이퍼파라미터 추가\n",
        "    cs.add_hyperparameters([\n",
        "        #CSH.UniformIntegerHyperparameter('batch_size_exp', lower=7, upper=9, default_value=8),\n",
        "        CSH.UniformFloatHyperparameter('dropout', lower=0.14, upper=0.142, default_value=0.141),\n",
        "        #CSH.UniformIntegerHyperparameter('expansion', lower=2, upper=6, default_value=3),\n",
        "        CSH.UniformFloatHyperparameter('initial_lr', lower=3.59e-5, upper=3.6e-5, log=True, default_value=3.593e-5),\n",
        "        CSH.UniformFloatHyperparameter('l2', lower=2.21e-5, upper=2.22e-5, log=True, default_value=2.213e-5),\n",
        "        CSH.UniformFloatHyperparameter('momentum', lower=0.99, upper=1, default_value=0.999),\n",
        "        CSH.UniformFloatHyperparameter('reduce_lr_factor', lower=0.57, upper=0.58, default_value=0.577),\n",
        "        #CSH.UniformIntegerHyperparameter('reduce_lr_patience', lower=4, upper=8, default_value=6),\n",
        "        ])\n",
        "\n",
        "    return cs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9js2LuZxVcA"
      },
      "source": [
        "# 재현\n",
        "무작위성을 감안하여 같은 하이퍼파라미터로 100 epoch를 3번 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSWmrIg0xRUq",
        "outputId": "98d7c298-20fc-46d9-d1a0-dbe9dd48e073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Hyperparameters: {'dropout': 0.14199653633808507, 'initial_lr': 3.592049887883645e-05, 'l2': 2.215599603422172e-05, 'momentum': 0.9951929071477241, 'reduce_lr_factor': 0.5745166438366855}\n",
            "Epoch 1/100\n",
            "188/188 [==============================] - 28s 83ms/step - loss: 0.7761 - categorical_accuracy: 0.7460 - val_loss: 21.1882 - val_categorical_accuracy: 0.1102 - lr: 3.5921e-05\n",
            "Epoch 2/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1398 - categorical_accuracy: 0.9693 - val_loss: 1.4459 - val_categorical_accuracy: 0.8634 - lr: 3.5921e-05\n",
            "Epoch 3/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1319 - categorical_accuracy: 0.9768 - val_loss: 0.9678 - val_categorical_accuracy: 0.8418 - lr: 3.5921e-05\n",
            "Epoch 4/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1231 - categorical_accuracy: 0.9810 - val_loss: 0.2349 - val_categorical_accuracy: 0.9607 - lr: 3.5921e-05\n",
            "Epoch 5/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.1145 - categorical_accuracy: 0.9837 - val_loss: 0.1992 - val_categorical_accuracy: 0.9605 - lr: 3.5921e-05\n",
            "Epoch 6/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1043 - categorical_accuracy: 0.9860 - val_loss: 0.1618 - val_categorical_accuracy: 0.9681 - lr: 3.5921e-05\n",
            "Epoch 7/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0958 - categorical_accuracy: 0.9870 - val_loss: 0.1212 - val_categorical_accuracy: 0.9787 - lr: 3.5921e-05\n",
            "Epoch 8/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0909 - categorical_accuracy: 0.9865 - val_loss: 0.1284 - val_categorical_accuracy: 0.9768 - lr: 3.5921e-05\n",
            "Epoch 9/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0828 - categorical_accuracy: 0.9882 - val_loss: 0.1470 - val_categorical_accuracy: 0.9685 - lr: 3.5921e-05\n",
            "Epoch 10/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0849 - categorical_accuracy: 0.9868 - val_loss: 0.1028 - val_categorical_accuracy: 0.9835 - lr: 3.5921e-05\n",
            "Epoch 11/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0778 - categorical_accuracy: 0.9895 - val_loss: 0.0951 - val_categorical_accuracy: 0.9832 - lr: 3.5921e-05\n",
            "Epoch 12/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0757 - categorical_accuracy: 0.9891 - val_loss: 0.0965 - val_categorical_accuracy: 0.9843 - lr: 3.5921e-05\n",
            "Epoch 13/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0708 - categorical_accuracy: 0.9897 - val_loss: 0.0844 - val_categorical_accuracy: 0.9851 - lr: 3.5921e-05\n",
            "Epoch 14/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0717 - categorical_accuracy: 0.9896 - val_loss: 0.0817 - val_categorical_accuracy: 0.9871 - lr: 3.5921e-05\n",
            "Epoch 15/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0709 - categorical_accuracy: 0.9891 - val_loss: 0.2315 - val_categorical_accuracy: 0.9463 - lr: 3.5921e-05\n",
            "Epoch 16/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0679 - categorical_accuracy: 0.9899 - val_loss: 0.2155 - val_categorical_accuracy: 0.9541 - lr: 3.5921e-05\n",
            "Epoch 17/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0671 - categorical_accuracy: 0.9905 - val_loss: 0.0859 - val_categorical_accuracy: 0.9857 - lr: 3.5921e-05\n",
            "Epoch 18/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0662 - categorical_accuracy: 0.9903 - val_loss: 0.0880 - val_categorical_accuracy: 0.9847 - lr: 3.5921e-05\n",
            "Epoch 19/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0670 - categorical_accuracy: 0.9896 - val_loss: 0.0951 - val_categorical_accuracy: 0.9814 - lr: 2.0637e-05\n",
            "Epoch 20/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0616 - categorical_accuracy: 0.9915 - val_loss: 0.0671 - val_categorical_accuracy: 0.9900 - lr: 2.0637e-05\n",
            "Epoch 21/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0586 - categorical_accuracy: 0.9919 - val_loss: 0.0625 - val_categorical_accuracy: 0.9912 - lr: 2.0637e-05\n",
            "Epoch 22/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0552 - categorical_accuracy: 0.9926 - val_loss: 0.0538 - val_categorical_accuracy: 0.9931 - lr: 2.0637e-05\n",
            "Epoch 23/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0512 - categorical_accuracy: 0.9933 - val_loss: 0.0563 - val_categorical_accuracy: 0.9921 - lr: 2.0637e-05\n",
            "Epoch 24/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0492 - categorical_accuracy: 0.9937 - val_loss: 0.0573 - val_categorical_accuracy: 0.9918 - lr: 2.0637e-05\n",
            "Epoch 25/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0463 - categorical_accuracy: 0.9939 - val_loss: 0.0669 - val_categorical_accuracy: 0.9877 - lr: 2.0637e-05\n",
            "Epoch 26/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0458 - categorical_accuracy: 0.9938 - val_loss: 0.0660 - val_categorical_accuracy: 0.9896 - lr: 2.0637e-05\n",
            "Epoch 27/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0470 - categorical_accuracy: 0.9933 - val_loss: 0.0489 - val_categorical_accuracy: 0.9928 - lr: 1.1856e-05\n",
            "Epoch 28/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0398 - categorical_accuracy: 0.9948 - val_loss: 0.0542 - val_categorical_accuracy: 0.9922 - lr: 1.1856e-05\n",
            "Epoch 29/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0398 - categorical_accuracy: 0.9949 - val_loss: 0.0472 - val_categorical_accuracy: 0.9923 - lr: 1.1856e-05\n",
            "Epoch 30/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0389 - categorical_accuracy: 0.9950 - val_loss: 0.0477 - val_categorical_accuracy: 0.9931 - lr: 1.1856e-05\n",
            "Epoch 31/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0362 - categorical_accuracy: 0.9955 - val_loss: 0.0451 - val_categorical_accuracy: 0.9933 - lr: 6.8116e-06\n",
            "Epoch 32/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0350 - categorical_accuracy: 0.9958 - val_loss: 0.0479 - val_categorical_accuracy: 0.9921 - lr: 6.8116e-06\n",
            "Epoch 33/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0317 - categorical_accuracy: 0.9966 - val_loss: 0.0426 - val_categorical_accuracy: 0.9937 - lr: 6.8116e-06\n",
            "Epoch 34/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0312 - categorical_accuracy: 0.9966 - val_loss: 0.0425 - val_categorical_accuracy: 0.9945 - lr: 6.8116e-06\n",
            "Epoch 35/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0297 - categorical_accuracy: 0.9970 - val_loss: 0.0429 - val_categorical_accuracy: 0.9936 - lr: 6.8116e-06\n",
            "Epoch 36/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0288 - categorical_accuracy: 0.9972 - val_loss: 0.0436 - val_categorical_accuracy: 0.9935 - lr: 6.8116e-06\n",
            "Epoch 37/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0290 - categorical_accuracy: 0.9970 - val_loss: 0.0448 - val_categorical_accuracy: 0.9936 - lr: 6.8116e-06\n",
            "Epoch 38/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0282 - categorical_accuracy: 0.9969 - val_loss: 0.0428 - val_categorical_accuracy: 0.9942 - lr: 6.8116e-06\n",
            "Epoch 39/100\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0274 - categorical_accuracy: 0.9970 - val_loss: 0.0405 - val_categorical_accuracy: 0.9949 - lr: 3.9134e-06\n",
            "Epoch 40/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0264 - categorical_accuracy: 0.9972 - val_loss: 0.0463 - val_categorical_accuracy: 0.9934 - lr: 3.9134e-06\n",
            "Epoch 41/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0252 - categorical_accuracy: 0.9976 - val_loss: 0.0384 - val_categorical_accuracy: 0.9949 - lr: 3.9134e-06\n",
            "Epoch 42/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0239 - categorical_accuracy: 0.9977 - val_loss: 0.0364 - val_categorical_accuracy: 0.9952 - lr: 3.9134e-06\n",
            "Epoch 43/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0230 - categorical_accuracy: 0.9981 - val_loss: 0.0394 - val_categorical_accuracy: 0.9944 - lr: 3.9134e-06\n",
            "Epoch 44/100\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0229 - categorical_accuracy: 0.9980 - val_loss: 0.0394 - val_categorical_accuracy: 0.9946 - lr: 3.9134e-06\n",
            "Epoch 45/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0222 - categorical_accuracy: 0.9981 - val_loss: 0.0361 - val_categorical_accuracy: 0.9949 - lr: 3.9134e-06\n",
            "Epoch 46/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0223 - categorical_accuracy: 0.9979 - val_loss: 0.0421 - val_categorical_accuracy: 0.9940 - lr: 3.9134e-06\n",
            "Epoch 47/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0214 - categorical_accuracy: 0.9980 - val_loss: 0.0363 - val_categorical_accuracy: 0.9946 - lr: 2.2483e-06\n",
            "Epoch 48/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0210 - categorical_accuracy: 0.9984 - val_loss: 0.0359 - val_categorical_accuracy: 0.9947 - lr: 2.2483e-06\n",
            "Epoch 49/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0216 - categorical_accuracy: 0.9980 - val_loss: 0.0377 - val_categorical_accuracy: 0.9949 - lr: 2.2483e-06\n",
            "Epoch 50/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0198 - categorical_accuracy: 0.9985 - val_loss: 0.0366 - val_categorical_accuracy: 0.9947 - lr: 2.2483e-06\n",
            "Epoch 51/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0203 - categorical_accuracy: 0.9984 - val_loss: 0.0364 - val_categorical_accuracy: 0.9952 - lr: 1.2917e-06\n",
            "Epoch 52/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0193 - categorical_accuracy: 0.9986 - val_loss: 0.0367 - val_categorical_accuracy: 0.9943 - lr: 1.2917e-06\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0300 - categorical_accuracy: 0.9955\n",
            "current iter:  1\n",
            "Hyperparameters: {'dropout': 0.14008442807036084, 'initial_lr': 3.596776741926716e-05, 'l2': 2.2170379319306128e-05, 'momentum': 0.9954641260540464, 'reduce_lr_factor': 0.5727002413145358}\n",
            "Epoch 1/100\n",
            "188/188 [==============================] - 22s 78ms/step - loss: 0.7723 - categorical_accuracy: 0.7526 - val_loss: 21.1156 - val_categorical_accuracy: 0.1102 - lr: 3.5968e-05\n",
            "Epoch 2/100\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.1429 - categorical_accuracy: 0.9696 - val_loss: 14.1187 - val_categorical_accuracy: 0.2024 - lr: 3.5968e-05\n",
            "Epoch 3/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1313 - categorical_accuracy: 0.9786 - val_loss: 0.9015 - val_categorical_accuracy: 0.8553 - lr: 3.5968e-05\n",
            "Epoch 4/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1226 - categorical_accuracy: 0.9821 - val_loss: 0.3201 - val_categorical_accuracy: 0.9487 - lr: 3.5968e-05\n",
            "Epoch 5/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1169 - categorical_accuracy: 0.9845 - val_loss: 0.5437 - val_categorical_accuracy: 0.8823 - lr: 3.5968e-05\n",
            "Epoch 6/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.1075 - categorical_accuracy: 0.9863 - val_loss: 0.1939 - val_categorical_accuracy: 0.9657 - lr: 3.5968e-05\n",
            "Epoch 7/100\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0994 - categorical_accuracy: 0.9867 - val_loss: 0.2890 - val_categorical_accuracy: 0.9285 - lr: 3.5968e-05\n",
            "Epoch 8/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0896 - categorical_accuracy: 0.9882 - val_loss: 0.1429 - val_categorical_accuracy: 0.9724 - lr: 3.5968e-05\n",
            "Epoch 9/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0904 - categorical_accuracy: 0.9873 - val_loss: 0.1111 - val_categorical_accuracy: 0.9808 - lr: 3.5968e-05\n",
            "Epoch 10/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0797 - categorical_accuracy: 0.9889 - val_loss: 0.1390 - val_categorical_accuracy: 0.9739 - lr: 3.5968e-05\n",
            "Epoch 11/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0800 - categorical_accuracy: 0.9882 - val_loss: 0.2881 - val_categorical_accuracy: 0.9260 - lr: 3.5968e-05\n",
            "Epoch 12/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0758 - categorical_accuracy: 0.9892 - val_loss: 0.1523 - val_categorical_accuracy: 0.9680 - lr: 3.5968e-05\n",
            "Epoch 13/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0759 - categorical_accuracy: 0.9889 - val_loss: 0.2322 - val_categorical_accuracy: 0.9467 - lr: 3.5968e-05\n",
            "Epoch 14/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0752 - categorical_accuracy: 0.9888 - val_loss: 0.0989 - val_categorical_accuracy: 0.9837 - lr: 2.0599e-05\n",
            "Epoch 15/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0702 - categorical_accuracy: 0.9904 - val_loss: 0.0791 - val_categorical_accuracy: 0.9888 - lr: 2.0599e-05\n",
            "Epoch 16/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0645 - categorical_accuracy: 0.9915 - val_loss: 0.0708 - val_categorical_accuracy: 0.9904 - lr: 2.0599e-05\n",
            "Epoch 17/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0605 - categorical_accuracy: 0.9925 - val_loss: 0.0809 - val_categorical_accuracy: 0.9873 - lr: 2.0599e-05\n",
            "Epoch 18/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0566 - categorical_accuracy: 0.9931 - val_loss: 0.0789 - val_categorical_accuracy: 0.9862 - lr: 2.0599e-05\n",
            "Epoch 19/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0552 - categorical_accuracy: 0.9928 - val_loss: 0.0659 - val_categorical_accuracy: 0.9895 - lr: 2.0599e-05\n",
            "Epoch 20/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0535 - categorical_accuracy: 0.9926 - val_loss: 0.0594 - val_categorical_accuracy: 0.9903 - lr: 2.0599e-05\n",
            "Epoch 21/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0513 - categorical_accuracy: 0.9932 - val_loss: 0.0610 - val_categorical_accuracy: 0.9908 - lr: 1.1797e-05\n",
            "Epoch 22/100\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 0.0468 - categorical_accuracy: 0.9938 - val_loss: 0.0539 - val_categorical_accuracy: 0.9923 - lr: 1.1797e-05\n",
            "Epoch 23/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0434 - categorical_accuracy: 0.9951 - val_loss: 0.0556 - val_categorical_accuracy: 0.9919 - lr: 1.1797e-05\n",
            "Epoch 24/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0433 - categorical_accuracy: 0.9948 - val_loss: 0.0507 - val_categorical_accuracy: 0.9932 - lr: 1.1797e-05\n",
            "Epoch 25/100\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0418 - categorical_accuracy: 0.9947 - val_loss: 0.0473 - val_categorical_accuracy: 0.9929 - lr: 1.1797e-05\n",
            "Epoch 26/100\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0397 - categorical_accuracy: 0.9951 - val_loss: 0.0532 - val_categorical_accuracy: 0.9902 - lr: 1.1797e-05\n",
            "Epoch 27/100\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0378 - categorical_accuracy: 0.9957 - val_loss: 0.0492 - val_categorical_accuracy: 0.9926 - lr: 1.1797e-05\n",
            "Epoch 28/100\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0383 - categorical_accuracy: 0.9949 - val_loss: 0.0514 - val_categorical_accuracy: 0.9922 - lr: 1.1797e-05\n",
            "Epoch 29/100\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0365 - categorical_accuracy: 0.9954 - val_loss: 0.0476 - val_categorical_accuracy: 0.9925 - lr: 6.7561e-06\n",
            "Epoch 30/100\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0356 - categorical_accuracy: 0.9954 - val_loss: 0.0451 - val_categorical_accuracy: 0.9935 - lr: 6.7561e-06\n",
            "Epoch 31/100\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0329 - categorical_accuracy: 0.9961 - val_loss: 0.0479 - val_categorical_accuracy: 0.9928 - lr: 6.7561e-06\n",
            "Epoch 32/100\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0320 - categorical_accuracy: 0.9964 - val_loss: 0.0410 - val_categorical_accuracy: 0.9937 - lr: 6.7561e-06\n",
            "Epoch 33/100\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0308 - categorical_accuracy: 0.9964 - val_loss: 0.0411 - val_categorical_accuracy: 0.9934 - lr: 6.7561e-06\n",
            "Epoch 34/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0294 - categorical_accuracy: 0.9965 - val_loss: 0.0391 - val_categorical_accuracy: 0.9939 - lr: 6.7561e-06\n",
            "Epoch 35/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0284 - categorical_accuracy: 0.9970 - val_loss: 0.0431 - val_categorical_accuracy: 0.9932 - lr: 6.7561e-06\n",
            "Epoch 36/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0281 - categorical_accuracy: 0.9967 - val_loss: 0.0402 - val_categorical_accuracy: 0.9938 - lr: 6.7561e-06\n",
            "Epoch 37/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0272 - categorical_accuracy: 0.9970 - val_loss: 0.0424 - val_categorical_accuracy: 0.9933 - lr: 6.7561e-06\n",
            "Epoch 38/100\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0279 - categorical_accuracy: 0.9965 - val_loss: 0.0390 - val_categorical_accuracy: 0.9944 - lr: 6.7561e-06\n",
            "Epoch 39/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0276 - categorical_accuracy: 0.9966 - val_loss: 0.0420 - val_categorical_accuracy: 0.9936 - lr: 6.7561e-06\n",
            "Epoch 40/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0269 - categorical_accuracy: 0.9971 - val_loss: 0.0408 - val_categorical_accuracy: 0.9934 - lr: 6.7561e-06\n",
            "Epoch 41/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0266 - categorical_accuracy: 0.9968 - val_loss: 0.0376 - val_categorical_accuracy: 0.9942 - lr: 6.7561e-06\n",
            "Epoch 42/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0258 - categorical_accuracy: 0.9968 - val_loss: 0.0403 - val_categorical_accuracy: 0.9940 - lr: 6.7561e-06\n",
            "Epoch 43/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0245 - categorical_accuracy: 0.9971 - val_loss: 0.0375 - val_categorical_accuracy: 0.9942 - lr: 3.8692e-06\n",
            "Epoch 44/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0236 - categorical_accuracy: 0.9973 - val_loss: 0.0379 - val_categorical_accuracy: 0.9946 - lr: 3.8692e-06\n",
            "Epoch 45/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0230 - categorical_accuracy: 0.9974 - val_loss: 0.0376 - val_categorical_accuracy: 0.9940 - lr: 3.8692e-06\n",
            "Epoch 46/100\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0226 - categorical_accuracy: 0.9976 - val_loss: 0.0438 - val_categorical_accuracy: 0.9930 - lr: 3.8692e-06\n",
            "Epoch 47/100\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 0.0225 - categorical_accuracy: 0.9976 - val_loss: 0.0375 - val_categorical_accuracy: 0.9945 - lr: 3.8692e-06\n",
            "Epoch 48/100\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0215 - categorical_accuracy: 0.9977 - val_loss: 0.0369 - val_categorical_accuracy: 0.9937 - lr: 3.8692e-06\n",
            "Epoch 49/100\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0225 - categorical_accuracy: 0.9975 - val_loss: 0.0456 - val_categorical_accuracy: 0.9930 - lr: 2.2159e-06\n",
            "Epoch 50/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0213 - categorical_accuracy: 0.9979 - val_loss: 0.0355 - val_categorical_accuracy: 0.9945 - lr: 2.2159e-06\n",
            "Epoch 51/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0200 - categorical_accuracy: 0.9982 - val_loss: 0.0358 - val_categorical_accuracy: 0.9943 - lr: 2.2159e-06\n",
            "Epoch 52/100\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0194 - categorical_accuracy: 0.9984 - val_loss: 0.0360 - val_categorical_accuracy: 0.9948 - lr: 2.2159e-06\n",
            "Epoch 53/100\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0188 - categorical_accuracy: 0.9985 - val_loss: 0.0342 - val_categorical_accuracy: 0.9952 - lr: 2.2159e-06\n",
            "Epoch 54/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0192 - categorical_accuracy: 0.9983 - val_loss: 0.0365 - val_categorical_accuracy: 0.9943 - lr: 2.2159e-06\n",
            "Epoch 55/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0179 - categorical_accuracy: 0.9986 - val_loss: 0.0349 - val_categorical_accuracy: 0.9945 - lr: 2.2159e-06\n",
            "Epoch 56/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0178 - categorical_accuracy: 0.9986 - val_loss: 0.0347 - val_categorical_accuracy: 0.9950 - lr: 2.2159e-06\n",
            "Epoch 57/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0176 - categorical_accuracy: 0.9986 - val_loss: 0.0346 - val_categorical_accuracy: 0.9948 - lr: 2.2159e-06\n",
            "Epoch 58/100\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0178 - categorical_accuracy: 0.9984 - val_loss: 0.0348 - val_categorical_accuracy: 0.9947 - lr: 1.2690e-06\n",
            "Epoch 59/100\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0171 - categorical_accuracy: 0.9988 - val_loss: 0.0356 - val_categorical_accuracy: 0.9948 - lr: 1.2690e-06\n",
            "Epoch 60/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0168 - categorical_accuracy: 0.9989 - val_loss: 0.0349 - val_categorical_accuracy: 0.9952 - lr: 1.2690e-06\n",
            "Epoch 61/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0163 - categorical_accuracy: 0.9989 - val_loss: 0.0347 - val_categorical_accuracy: 0.9949 - lr: 1.2690e-06\n",
            "Epoch 62/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0167 - categorical_accuracy: 0.9987 - val_loss: 0.0346 - val_categorical_accuracy: 0.9949 - lr: 7.2678e-07\n",
            "Epoch 63/100\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 0.0160 - categorical_accuracy: 0.9990 - val_loss: 0.0339 - val_categorical_accuracy: 0.9948 - lr: 7.2678e-07\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0274 - categorical_accuracy: 0.9962\n",
            "current iter:  2\n",
            "Hyperparameters: {'dropout': 0.14046147906063702, 'initial_lr': 3.599831366719112e-05, 'l2': 2.2131406818219345e-05, 'momentum': 0.9912941040202504, 'reduce_lr_factor': 0.5796645372119035}\n",
            "Epoch 1/100\n",
            "188/188 [==============================] - 23s 79ms/step - loss: 0.6975 - categorical_accuracy: 0.7733 - val_loss: 14.4257 - val_categorical_accuracy: 0.1102 - lr: 3.5998e-05\n",
            "Epoch 2/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.1189 - categorical_accuracy: 0.9714 - val_loss: 0.5005 - val_categorical_accuracy: 0.8811 - lr: 3.5998e-05\n",
            "Epoch 3/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0941 - categorical_accuracy: 0.9804 - val_loss: 0.1472 - val_categorical_accuracy: 0.9664 - lr: 3.5998e-05\n",
            "Epoch 4/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0802 - categorical_accuracy: 0.9852 - val_loss: 0.1446 - val_categorical_accuracy: 0.9667 - lr: 3.5998e-05\n",
            "Epoch 5/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0798 - categorical_accuracy: 0.9854 - val_loss: 0.5796 - val_categorical_accuracy: 0.8687 - lr: 3.5998e-05\n",
            "Epoch 6/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0753 - categorical_accuracy: 0.9862 - val_loss: 0.1218 - val_categorical_accuracy: 0.9721 - lr: 3.5998e-05\n",
            "Epoch 7/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0718 - categorical_accuracy: 0.9869 - val_loss: 0.2109 - val_categorical_accuracy: 0.9450 - lr: 3.5998e-05\n",
            "Epoch 8/100\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 0.0697 - categorical_accuracy: 0.9879 - val_loss: 0.2956 - val_categorical_accuracy: 0.9285 - lr: 3.5998e-05\n",
            "Epoch 9/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0656 - categorical_accuracy: 0.9891 - val_loss: 0.0780 - val_categorical_accuracy: 0.9851 - lr: 3.5998e-05\n",
            "Epoch 10/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0602 - categorical_accuracy: 0.9904 - val_loss: 0.0769 - val_categorical_accuracy: 0.9851 - lr: 3.5998e-05\n",
            "Epoch 11/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0570 - categorical_accuracy: 0.9911 - val_loss: 0.0839 - val_categorical_accuracy: 0.9847 - lr: 3.5998e-05\n",
            "Epoch 12/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0573 - categorical_accuracy: 0.9905 - val_loss: 0.0593 - val_categorical_accuracy: 0.9899 - lr: 3.5998e-05\n",
            "Epoch 13/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0581 - categorical_accuracy: 0.9906 - val_loss: 0.0745 - val_categorical_accuracy: 0.9857 - lr: 3.5998e-05\n",
            "Epoch 14/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0542 - categorical_accuracy: 0.9915 - val_loss: 0.0932 - val_categorical_accuracy: 0.9811 - lr: 3.5998e-05\n",
            "Epoch 15/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0551 - categorical_accuracy: 0.9909 - val_loss: 0.0868 - val_categorical_accuracy: 0.9852 - lr: 3.5998e-05\n",
            "Epoch 16/100\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 0.0526 - categorical_accuracy: 0.9918 - val_loss: 0.0825 - val_categorical_accuracy: 0.9833 - lr: 3.5998e-05\n",
            "Epoch 17/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0523 - categorical_accuracy: 0.9917 - val_loss: 0.0612 - val_categorical_accuracy: 0.9903 - lr: 2.0867e-05\n",
            "Epoch 18/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0457 - categorical_accuracy: 0.9936 - val_loss: 0.0522 - val_categorical_accuracy: 0.9925 - lr: 2.0867e-05\n",
            "Epoch 19/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0415 - categorical_accuracy: 0.9949 - val_loss: 0.0561 - val_categorical_accuracy: 0.9902 - lr: 2.0867e-05\n",
            "Epoch 20/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0422 - categorical_accuracy: 0.9941 - val_loss: 0.0540 - val_categorical_accuracy: 0.9921 - lr: 2.0867e-05\n",
            "Epoch 21/100\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0404 - categorical_accuracy: 0.9945 - val_loss: 0.0570 - val_categorical_accuracy: 0.9908 - lr: 2.0867e-05\n",
            "Epoch 22/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0383 - categorical_accuracy: 0.9948 - val_loss: 0.0552 - val_categorical_accuracy: 0.9912 - lr: 2.0867e-05\n",
            "Epoch 23/100\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0380 - categorical_accuracy: 0.9949 - val_loss: 0.0520 - val_categorical_accuracy: 0.9914 - lr: 1.2096e-05\n",
            "Epoch 24/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0342 - categorical_accuracy: 0.9959 - val_loss: 0.0533 - val_categorical_accuracy: 0.9915 - lr: 1.2096e-05\n",
            "Epoch 25/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0333 - categorical_accuracy: 0.9962 - val_loss: 0.0582 - val_categorical_accuracy: 0.9903 - lr: 1.2096e-05\n",
            "Epoch 26/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0314 - categorical_accuracy: 0.9965 - val_loss: 0.0440 - val_categorical_accuracy: 0.9933 - lr: 1.2096e-05\n",
            "Epoch 27/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0307 - categorical_accuracy: 0.9967 - val_loss: 0.0491 - val_categorical_accuracy: 0.9924 - lr: 1.2096e-05\n",
            "Epoch 28/100\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0289 - categorical_accuracy: 0.9967 - val_loss: 0.0431 - val_categorical_accuracy: 0.9937 - lr: 1.2096e-05\n",
            "Epoch 29/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0292 - categorical_accuracy: 0.9968 - val_loss: 0.0540 - val_categorical_accuracy: 0.9912 - lr: 1.2096e-05\n",
            "Epoch 30/100\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0287 - categorical_accuracy: 0.9966 - val_loss: 0.0405 - val_categorical_accuracy: 0.9940 - lr: 1.2096e-05\n",
            "Epoch 31/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0291 - categorical_accuracy: 0.9964 - val_loss: 0.0369 - val_categorical_accuracy: 0.9946 - lr: 1.2096e-05\n",
            "Epoch 32/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0263 - categorical_accuracy: 0.9971 - val_loss: 0.0417 - val_categorical_accuracy: 0.9937 - lr: 1.2096e-05\n",
            "Epoch 33/100\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 0.0263 - categorical_accuracy: 0.9969 - val_loss: 0.0443 - val_categorical_accuracy: 0.9926 - lr: 1.2096e-05\n",
            "Epoch 34/100\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0259 - categorical_accuracy: 0.9971 - val_loss: 0.0461 - val_categorical_accuracy: 0.9930 - lr: 1.2096e-05\n",
            "Epoch 35/100\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0262 - categorical_accuracy: 0.9967 - val_loss: 0.0484 - val_categorical_accuracy: 0.9927 - lr: 1.2096e-05\n",
            "Epoch 36/100\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0259 - categorical_accuracy: 0.9964 - val_loss: 0.0400 - val_categorical_accuracy: 0.9934 - lr: 7.0115e-06\n",
            "Epoch 37/100\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.0229 - categorical_accuracy: 0.9976 - val_loss: 0.0389 - val_categorical_accuracy: 0.9942 - lr: 7.0115e-06\n",
            "Epoch 38/100\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.0227 - categorical_accuracy: 0.9979 - val_loss: 0.0390 - val_categorical_accuracy: 0.9941 - lr: 7.0115e-06\n",
            "Epoch 39/100\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0213 - categorical_accuracy: 0.9980 - val_loss: 0.0361 - val_categorical_accuracy: 0.9947 - lr: 7.0115e-06\n",
            "Epoch 40/100\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0217 - categorical_accuracy: 0.9979 - val_loss: 0.0381 - val_categorical_accuracy: 0.9941 - lr: 4.0643e-06\n",
            "Epoch 41/100\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.0204 - categorical_accuracy: 0.9984 - val_loss: 0.0386 - val_categorical_accuracy: 0.9945 - lr: 4.0643e-06\n",
            "Epoch 42/100\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 0.0201 - categorical_accuracy: 0.9983 - val_loss: 0.0374 - val_categorical_accuracy: 0.9943 - lr: 4.0643e-06\n",
            "Epoch 43/100\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.0194 - categorical_accuracy: 0.9985 - val_loss: 0.0393 - val_categorical_accuracy: 0.9943 - lr: 4.0643e-06\n",
            "Epoch 44/100\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0190 - categorical_accuracy: 0.9984 - val_loss: 0.0343 - val_categorical_accuracy: 0.9952 - lr: 2.3559e-06\n",
            "Epoch 45/100\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.0181 - categorical_accuracy: 0.9988 - val_loss: 0.0348 - val_categorical_accuracy: 0.9952 - lr: 2.3559e-06\n",
            "Epoch 46/100\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.0180 - categorical_accuracy: 0.9987 - val_loss: 0.0367 - val_categorical_accuracy: 0.9945 - lr: 2.3559e-06\n",
            "Epoch 47/100\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.0176 - categorical_accuracy: 0.9987 - val_loss: 0.0369 - val_categorical_accuracy: 0.9949 - lr: 2.3559e-06\n",
            "Epoch 48/100\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.0179 - categorical_accuracy: 0.9987 - val_loss: 0.0353 - val_categorical_accuracy: 0.9951 - lr: 2.3559e-06\n",
            "Epoch 49/100\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.0174 - categorical_accuracy: 0.9990 - val_loss: 0.0362 - val_categorical_accuracy: 0.9951 - lr: 1.3657e-06\n",
            "Epoch 50/100\n",
            "188/188 [==============================] - 14s 72ms/step - loss: 0.0172 - categorical_accuracy: 0.9989 - val_loss: 0.0364 - val_categorical_accuracy: 0.9950 - lr: 1.3657e-06\n",
            "Epoch 51/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0168 - categorical_accuracy: 0.9990 - val_loss: 0.0365 - val_categorical_accuracy: 0.9948 - lr: 1.3657e-06\n",
            "Epoch 52/100\n",
            "188/188 [==============================] - 13s 72ms/step - loss: 0.0166 - categorical_accuracy: 0.9990 - val_loss: 0.0354 - val_categorical_accuracy: 0.9950 - lr: 1.3657e-06\n",
            "Epoch 53/100\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.0165 - categorical_accuracy: 0.9991 - val_loss: 0.0351 - val_categorical_accuracy: 0.9951 - lr: 7.9162e-07\n",
            "Epoch 54/100\n",
            "188/188 [==============================] - 14s 73ms/step - loss: 0.0163 - categorical_accuracy: 0.9991 - val_loss: 0.0353 - val_categorical_accuracy: 0.9950 - lr: 7.9162e-07\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0278 - categorical_accuracy: 0.9961\n",
            "current iter:  3\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "import hpbandster.core.result as hpres\n",
        "import time\n",
        "from google.colab import drive\n",
        "from hpbandster.core.result import json_result_logger\n",
        "import hpbandster.core.nameserver as hpns\n",
        "from hpbandster.optimizers import BOHB\n",
        "\n",
        "# Google Drive 마운트\n",
        "drive.mount('/content/drive')\n",
        "SAVE_DIR = '/content/drive/My Drive/HW4_test_results'  # 저장할 경로 설정\n",
        "\n",
        "# 결과 저장 폴더 생성 (없을 경우)\n",
        "if not os.path.exists(SAVE_DIR):\n",
        "    os.makedirs(SAVE_DIR)\n",
        "\n",
        "result_logger = hpres.json_result_logger(directory=SAVE_DIR, overwrite=True)\n",
        "\n",
        "# 네임 서버와 워커를 새로 시작하는 함수\n",
        "def start_new_ns_and_workers():\n",
        "    global NS, w\n",
        "    NS = hpns.NameServer(run_id='bohb', host='127.0.0.1', port=9090)  # 포트를 명시적으로 설정\n",
        "    NS.start()\n",
        "    w = MyWorker(nameserver='127.0.0.1', nameserver_port=9090, run_id='bohb')  # 동일한 포트로 설정\n",
        "    w.run(background=True)\n",
        "    time.sleep(2)  # 잠시 대기하여 워커가 네임 서버에 연결될 시간을 줍니다.\n",
        "\n",
        "start_new_ns_and_workers()\n",
        "\n",
        "# BOHB 설정\n",
        "try:\n",
        "    bohb = BOHB(\n",
        "        configspace=get_configspace(),\n",
        "        run_id='bohb',\n",
        "        nameserver='127.0.0.1',\n",
        "        min_budget=100,\n",
        "        max_budget=100,\n",
        "        result_logger=result_logger,  # 결과 로거 설정\n",
        "    )\n",
        "\n",
        "    # BOHB 실행 및 결과 저장\n",
        "    for i in range(3):\n",
        "        result = bohb.run(n_iterations=1)\n",
        "        print(\"current iter: \", result.num_iterations())\n",
        "        # iteration 종료 시 결과 저장\n",
        "        # 결과 저장\n",
        "        with open(os.path.join(SAVE_DIR, 'results.pkl'), 'wb') as fh:\n",
        "            pickle.dump(result, fh)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n작업이 중단되었습니다. 마지막 Iteration까지 결과가 저장되었습니다.\")\n",
        "finally:\n",
        "    bohb.shutdown(shutdown_workers=True)\n",
        "    NS.shutdown()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 결과 분석"
      ],
      "metadata": {
        "id": "uA7GHQYdcbDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Google Drive 마운트\n",
        "drive.mount('/content/drive')\n",
        "SAVE_DIR = '/content/drive/My Drive/HW4_test_results'  # 저장할 경로 설정\n",
        "# 저장된 결과 파일 경로\n",
        "result_file = os.path.join(SAVE_DIR, 'results.pkl')\n",
        "\n",
        "# 결과 불러오기\n",
        "with open(result_file, 'rb') as f:\n",
        "    result = pickle.load(f)\n",
        "\n",
        "# get all executed runs\n",
        "all_runs = result.get_all_runs()\n",
        "\n",
        "# get the 'dict' that translates config ids to the actual configurations\n",
        "id2conf = result.get_id2config_mapping()\n",
        "\n",
        "results = []\n",
        "for entry in all_runs:\n",
        "        test_accuracy = entry['info']['test_accuracy']\n",
        "        results.append(test_accuracy)\n",
        "\n",
        "# 실험 인덱스 생성\n",
        "indices = range(len(results))\n",
        "\n",
        "# 최고 테스트 정확도 값 추적\n",
        "max_accuracy = []\n",
        "current_max = 0\n",
        "for accuracy in results:\n",
        "    if accuracy > current_max:\n",
        "        current_max = accuracy\n",
        "    max_accuracy.append(current_max)\n",
        "\n",
        "# 테스트 정확도 그래프 그리기\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(indices, results, 'bo', label='Test Accuracy')\n",
        "\n",
        "# 최고 기록 점 표시\n",
        "for i, (x, y) in enumerate(zip(indices, results)):\n",
        "    if y == max_accuracy[i]:\n",
        "        plt.plot(x, y, 'ro')\n",
        "        plt.text(x, y, f'{y:.4f}', fontsize=9, verticalalignment='bottom', horizontalalignment='right')\n",
        "\n",
        "# 최고 기록을 잇는 선 그리기\n",
        "plt.plot(indices, max_accuracy, 'r-', label='High Score')\n",
        "\n",
        "# 세밀한 y축 범위 설정\n",
        "plt.ylim(0.96, 1.0)\n",
        "plt.yticks([0.96, 0.97, 0.98, 0.99, 1.0])\n",
        "\n",
        "# 그래프 라벨 및 제목 추가\n",
        "plt.xlabel('Experiment Index')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.title('Test Accuracy over Time')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "RVPx_De4dfQw",
        "outputId": "7840e68f-54b6-4d05-a8b3-d2564307e28c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}